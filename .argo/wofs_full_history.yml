kind: Workflow
metadata:
  generateName: wofs
  namespace: argo
spec:
  entrypoint: loop-map-wofs
  serviceAccountName: open-data-bucket-writer
    #serviceAccountName: public-bucket-writer
  podGC:
    strategy: OnPodSuccess
    deleteDelayDuration: 600s
  parallelism: 600
  podMetadata:
    labels:
      app: wofs
    annotations:
      karpenter.sh/do-not-disrupt: "true"
  nodeSelector:
    karpenter.sh/capacity-type: "spot"
  hostAliases:
    - ip: "52.92.184.90"
      hostnames:
        - "dep-public-staging.s3.us-west-2.amazonaws.com"
    - ip: "3.5.85.43"
      hostnames:
        - "dep-public-data.s3.us-west-2.amazonaws.com"
  arguments:
    parameters:
    - name: version
      value: "0.2.0"  # The version of the data product being made
    - name: image-tag
      value: "0.2.0dev7"
    - name: output-bucket
      value: "dep-public-data"
    - name: output-collection-root
      value: "https://stac.digitalearthpacific.org"
  templates:
  - name: loop-map-wofs
    retryStrategy:
      limit: "2"
      retryPolicy: "Always"
    dag:
      tasks:
        - name: generate-ids
          template: generate
          arguments:
            parameters:
              - name: limit
                value: "9999"
              - name: datetime
                value: "1984/2023" 
              - name: version
                value: "{{ workflow.parameters.version }}"
              - name: dataset-id
                value: "wofs_summary_alltime"
        - name: process-id
          depends: generate-ids.Succeeded
          template: process-wofs-tile
          retryStrategy:
            limit: "2"
            retryPolicy: "Always"
          arguments:
            parameters:
            - name: row
              value: "{{item.row}}"
            - name: column
              value: "{{item.column}}"
            - name: datetime
              value: "{{item.datetime}}"
            - name: version
              value: "{{ workflow.parameters.version }}"
          withParam: "{{ tasks.generate-ids.outputs.result }}"

  - name: generate
    inputs:
      parameters:
      - name: limit
      - name: datetime
      - name: version
      - name: dataset-id
    container:
      image: "ghcr.io/digitalearthpacific/dep-wofs:{{ workflow.parameters.image-tag }}"
      imagePullPolicy: IfNotPresent
      resources:
        requests: 
          memory: 100Mi
          cpu: 1.0
      command: [ python ]
      args:
        - dep_wofs/print_tasks.py
        - --datetime
        - "{{ inputs.parameters.datetime }}"
        - --version
        - "{{ inputs.parameters.version }}"
        - --limit
        - "{{ inputs.parameters.limit }}"
        - --dataset-id
        - "{{ inputs.parameters.dataset-id }}"
      env:
        - name: WOFS_BUCKET
          value: "{{ workflow.parameters.output-bucket }}"
        - name: OUTPUT_COLLECTION_ROOT
          value: "{{ workflow.parameters.output-collection-root }}"
  - name: process-wofs-tile
    inputs:
      parameters:
      - name: row
      - name: column
      - name: datetime
      - name: version
    container:
      image: "ghcr.io/digitalearthpacific/dep-wofs:{{ workflow.parameters.image-tag }}"
      imagePullPolicy: IfNotPresent
      resources:
        requests: 
          memory: 5Gi
          cpu: 4.0
        limits:
          cpu: 6.0
          memory: 15Gi
      command: [ python ]
      args:
        - dep_wofs/process_wofs_full_history_tile.py
        - --row
        - "{{ inputs.parameters.row }}"
        - --column
        - "{{ inputs.parameters.column }}"
        - --datetime
        - "{{ inputs.parameters.datetime }}"
        - --version
        - "{{ inputs.parameters.version }}"
      env:
        - name: DASK_ARRAY__RECHUNK__METHOD
          value: "tasks"
        - name: WOFS_BUCKET
          value: "{{ workflow.parameters.output-bucket }}"
        - name: OUTPUT_COLLECTION_ROOT
          value: "{{ workflow.parameters.output-collection-root }}"
